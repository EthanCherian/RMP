{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(\"scraped_comments.csv\").sample(n=500000, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.drop_duplicates(subset=\"comment_id\", keep=\"first\", inplace=True)\n",
    "\n",
    "reviews.dropna(subset=[\"comment\"], inplace=True)\n",
    "# drop rows containing only \"No Comments\" (default value assigned by RMP to a review that didn't enter a comment)\n",
    "reviews = reviews[reviews[\"comment\"] != \"No Comments\"]\n",
    "# replace all comments with less than 5 words with a NaN\n",
    "reviews[\"comment\"] = reviews[\"comment\"].apply(lambda x: x if len(x.split()) > 5 else None)\n",
    "# drop rows containing NaN comment\n",
    "reviews.dropna(subset=[\"comment\"], inplace=True)\n",
    "\n",
    "reviews.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ethan\\AppData\\Local\\Temp\\ipykernel_24264\\1115318851.py:1: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  reviews_html = reviews[reviews[\"comment\"].str.contains('&([a-zA-z]+|#\\d+);')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>The &amp;quot;Whip&amp;quot; is and always be a legend.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>I have never been treated this badly for askin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>On a facebook picture caption [of our 313 clas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>most people can not understand him. half the t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>This guy is just an ass, he thinks that he hon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comment\n",
       "17     The &quot;Whip&quot; is and always be a legend.\n",
       "32   I have never been treated this badly for askin...\n",
       "76   On a facebook picture caption [of our 313 clas...\n",
       "81   most people can not understand him. half the t...\n",
       "108  This guy is just an ass, he thinks that he hon..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_html = reviews[reviews[\"comment\"].str.contains('&([a-zA-z]+|#\\d+);')]\n",
    "reviews_html = reviews_html.loc[:, [\"comment\"]]\n",
    "reviews_html.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Whip is and always be a legend.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hello = re.sub('&([a-zA-z]+|#\\d+);', \"\", reviews_html[\"comment\"][17])\n",
    "hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "no_stop_words = []\n",
    "\n",
    "for i in range(reviews.shape[0]):\n",
    "    text = reviews[\"comment\"][i]\n",
    "    doc = nlp(text)\n",
    "\n",
    "    token_list = []\n",
    "    for token in doc:\n",
    "        token_list.append(token.lemma_)\n",
    "    \n",
    "    filtered_sent = []\n",
    "    for word in token_list:\n",
    "        lexeme = nlp.vocab[word]\n",
    "        if lexeme.is_stop == False:\n",
    "            filtered_sent.append(word)\n",
    "    \n",
    "    no_stop_words.append(\" \".join(filtered_sent))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "reviews[\"tokens\"] = reviews[\"comment\"].apply(lambda x: nlp(x))\n",
    "reviews[\"lemma_tokens\"] = reviews[\"tokens\"].apply(lambda x: \" \".join([token.lemma_ for token in x if token not in spacy.lang.en.stop_words.STOP_WORDS]))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing non-alphabetic characters (may want to keep numbers, will deal with that later)\n",
    "comments_proper = []\n",
    "\n",
    "for i in range(reviews.shape[0]):\n",
    "    review = no_stop_words[i]\n",
    "    review = re.sub('[^a-zA-Z\\s]+', ' ', review)\n",
    "    review = re.sub('\\s+', ' ', review)             # get rid of excess whitespace generated by spaCy's less-than-ideal tokenization\n",
    "    review = review.lower()                         # lowercase review for uniformity\n",
    "    comments_proper.append(review)\n",
    "\n",
    "comments = pd.Series(comments_proper, copy=False)\n",
    "comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist\n",
    "\n",
    "%matplotlib inline\n",
    "def freq_words(x, terms=30):        # function to plot most frequent words\n",
    "    all_words = \" \".join([text for text in x])\n",
    "    all_words = all_words.split()\n",
    "\n",
    "    fdist = FreqDist(all_words)\n",
    "    words_df = pd.DataFrame({\"word\":list(fdist.keys()), \"count\":list(fdist.values())})\n",
    "\n",
    "    d = words_df.nlargest(columns=\"count\", n=terms)\n",
    "    plt.figure(figsize=(25,5))\n",
    "    ax = sns.barplot(data=d, x=\"word\", y=\"count\")\n",
    "    ax.set(ylabel=\"Count\")\n",
    "    plt.show()\n",
    "\n",
    "freq_words(comments, terms=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def freq_bigrams(x, terms=30):        # function to plot most frequent words\n",
    "    all_words = \" \".join([text for text in x])\n",
    "    all_words = all_words.split()\n",
    "\n",
    "    bgs = nltk.bigrams(all_words)\n",
    "    fdist = FreqDist(bgs)\n",
    "    words_df = pd.DataFrame({\"word\":list(fdist.keys()), \"count\":list(fdist.values())})\n",
    "\n",
    "    d = words_df.nlargest(columns=\"count\", n=terms)\n",
    "    plt.figure(figsize=(25,5))\n",
    "    plt.xticks(rotation=45)\n",
    "    ax = sns.barplot(data=d, x=\"word\", y=\"count\")\n",
    "    ax.set(ylabel=\"Count\")\n",
    "    plt.show()\n",
    "\n",
    "freq_bigrams(comments, terms=35)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed8ce2715666cca47edfe3dc40f16f58fc193b5a7b06958e2ae06c97afdf9990"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
